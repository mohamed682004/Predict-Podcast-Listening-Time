{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow torch pyro-ppl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmwCmjGTD21-",
        "outputId": "0753fe2e-6888-4411-80fa-1fb5bfe881e8"
      },
      "id": "pmwCmjGTD21-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.11/dist-packages (1.9.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a360b39",
      "metadata": {
        "id": "5a360b39"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "import pyro.distributions as dist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Qv9ub_Hox8WZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv9ub_Hox8WZ",
        "outputId": "7285cb50-225e-47ae-9032-63732d292bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a7f80cb2",
      "metadata": {
        "id": "a7f80cb2"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6c6b25bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "6c6b25bd",
        "outputId": "1ddd797f-34dd-494e-f19f-21eede5b4704"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
              "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
              "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
              "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
              "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
              "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
              "\n",
              "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
              "0                       74.81        Thursday            Night   \n",
              "1                       66.95        Saturday        Afternoon   \n",
              "2                       69.97         Tuesday          Evening   \n",
              "3                       57.22          Monday          Morning   \n",
              "4                       80.07          Monday        Afternoon   \n",
              "\n",
              "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
              "0                          NaN            0.0          Positive   \n",
              "1                        75.95            2.0          Negative   \n",
              "2                         8.97            0.0          Negative   \n",
              "3                        78.70            2.0          Positive   \n",
              "4                        58.68            3.0           Neutral   \n",
              "\n",
              "   Listening_Time_minutes  \n",
              "0                31.41998  \n",
              "1                88.01241  \n",
              "2                44.92531  \n",
              "3                46.27824  \n",
              "4                75.61031  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-865f8644-54bc-4260-aa49-3071f4d6d623\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Podcast_Name</th>\n",
              "      <th>Episode_Title</th>\n",
              "      <th>Episode_Length_minutes</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Host_Popularity_percentage</th>\n",
              "      <th>Publication_Day</th>\n",
              "      <th>Publication_Time</th>\n",
              "      <th>Guest_Popularity_percentage</th>\n",
              "      <th>Number_of_Ads</th>\n",
              "      <th>Episode_Sentiment</th>\n",
              "      <th>Listening_Time_minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mystery Matters</td>\n",
              "      <td>Episode 98</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True Crime</td>\n",
              "      <td>74.81</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>Night</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>31.41998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Joke Junction</td>\n",
              "      <td>Episode 26</td>\n",
              "      <td>119.80</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>66.95</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>75.95</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Negative</td>\n",
              "      <td>88.01241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Study Sessions</td>\n",
              "      <td>Episode 16</td>\n",
              "      <td>73.90</td>\n",
              "      <td>Education</td>\n",
              "      <td>69.97</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>Evening</td>\n",
              "      <td>8.97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Negative</td>\n",
              "      <td>44.92531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Digital Digest</td>\n",
              "      <td>Episode 45</td>\n",
              "      <td>67.17</td>\n",
              "      <td>Technology</td>\n",
              "      <td>57.22</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Morning</td>\n",
              "      <td>78.70</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>46.27824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mind &amp; Body</td>\n",
              "      <td>Episode 86</td>\n",
              "      <td>110.51</td>\n",
              "      <td>Health</td>\n",
              "      <td>80.07</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>58.68</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>75.61031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-865f8644-54bc-4260-aa49-3071f4d6d623')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-865f8644-54bc-4260-aa49-3071f4d6d623 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-865f8644-54bc-4260-aa49-3071f4d6d623');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-849be0fd-f27b-4a29-a508-5318933602d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-849be0fd-f27b-4a29-a508-5318933602d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-849be0fd-f27b-4a29-a508-5318933602d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d863ea74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d863ea74",
        "outputId": "44e2a6f4-545e-4e06-9700-09efc60fc3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d503df9b77f4>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_data['Episode_Length_minutes'].fillna(train_data['Episode_Length_minutes'].median(), inplace=True)\n",
            "<ipython-input-6-d503df9b77f4>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_data['Guest_Popularity_percentage'].fillna(train_data['Guest_Popularity_percentage'].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Replace null values with Median\n",
        "train_data['Episode_Length_minutes'].fillna(train_data['Episode_Length_minutes'].median(), inplace=True)\n",
        "train_data['Guest_Popularity_percentage'].fillna(train_data['Guest_Popularity_percentage'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0758c397",
      "metadata": {
        "id": "0758c397"
      },
      "outputs": [],
      "source": [
        "# remove id column\n",
        "train_data = train_data.drop('id', axis=1)\n",
        "train_data = train_data.drop('Podcast_Name', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cecfa41e",
      "metadata": {
        "id": "cecfa41e"
      },
      "outputs": [],
      "source": [
        "# Remove the word 'Episode' from the Episode_Title column\n",
        "train_data['Episode_Title'] = train_data['Episode_Title'].str.replace('Episode', '', regex=False)\n",
        "# Change the Episode_Title name to Episode number\n",
        "train_data.rename(columns={'Episode_Title': 'Episode_Number'}, inplace=True)\n",
        "train_data['Episode_Number'] = train_data['Episode_Number'].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "yO15EVcfqpIg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO15EVcfqpIg",
        "outputId": "d862ccf2-f174-458d-c962-a1d3e3a1d084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 600000 samples\n",
            "Testing set size: 150000 samples\n"
          ]
        }
      ],
      "source": [
        "# Split features and target\n",
        "X = train_data.drop(columns=['Listening_Time_minutes'])\n",
        "y = train_data['Listening_Time_minutes']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Identify column types\n",
        "numerical_cols = ['Episode_Number', 'Episode_Length_minutes',\n",
        "                  'Host_Popularity_percentage', 'Guest_Popularity_percentage',\n",
        "                  'Number_of_Ads']\n",
        "numerical_cols = [col for col in numerical_cols if col in X.columns]\n",
        "categorical_cols = [col for col in X.columns if col not in numerical_cols]\n",
        "\n",
        "# Define transformers with scaling and one-hot encoding\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Fit + transform the training and test sets\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Convert all to float32\n",
        "X_train_np = X_train_processed.astype(np.float32)\n",
        "X_test_np = X_test_processed.astype(np.float32)\n",
        "y_train_np = y_train.to_numpy(dtype=np.float32)\n",
        "y_test_np = y_test.to_numpy(dtype=np.float32)\n",
        "\n",
        "print(f\"Training set size: {X_train_np.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test_np.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "hUHYqnmFE0ES",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUHYqnmFE0ES",
        "outputId": "16391ab5-6850-4786-9fc2-51c0aaccf937"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600000, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_train_np.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "z0k8MHPrEJ2O",
      "metadata": {
        "id": "z0k8MHPrEJ2O"
      },
      "outputs": [],
      "source": [
        "# Option 2: Impute (fill) NaNs, e.g. with mean\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_np = imputer.fit_transform(X_train_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "sWy-f235Gb3O",
      "metadata": {
        "id": "sWy-f235Gb3O"
      },
      "outputs": [],
      "source": [
        "# Initialize parameters\n",
        "np.random.seed(42)\n",
        "n_features = X_train_np.shape[1]\n",
        "weights = np.random.randn(n_features, 1).astype(np.float32) * 0.01\n",
        "bias = np.float32(0.0)\n",
        "noise_variance = np.float32(100.0)  # Match target variance\n",
        "prior_variance = np.float32(100.0)  # Stronger regularization\n",
        "learning_rate = np.float32(2e-5)\n",
        "n_iterations = 1000\n",
        "batch_size = 1024\n",
        "tol = 1e-4\n",
        "clip_norm = 10.0  # Gradient clipping threshold\n",
        "max_lr_reductions = 5  # Limit learning rate reductions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "V-l4xepPsjm4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-l4xepPsjm4",
        "outputId": "48b01d58-9de6-4337-cc32-248599b5d9bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: If shape errors persist, restart the Jupyter kernel to clear cached parameters.\n",
            "Starting training loop...\n",
            "[Iter 0000] Train ELBO: 155114.9300, Val ELBO: 299843.0684, LR: 7.00e-04\n",
            "Iteration 1/500 completed with 96 mini-batches.\n",
            "[Iter 0001] Train ELBO: 140556.5712, Val ELBO: 96393.1840, LR: 7.00e-04\n",
            "Iteration 2/500 completed with 96 mini-batches.\n",
            "[Iter 0002] Train ELBO: 124812.4526, Val ELBO: 236792.9739, LR: 7.00e-04\n",
            "Iteration 3/500 completed with 96 mini-batches.\n",
            "[Iter 0003] Train ELBO: 137242.3239, Val ELBO: 115510.5187, LR: 7.00e-04\n",
            "Iteration 4/500 completed with 96 mini-batches.\n",
            "[Iter 0004] Train ELBO: 122955.9965, Val ELBO: 108080.1381, LR: 7.00e-04\n",
            "Iteration 5/500 completed with 96 mini-batches.\n",
            "Iteration 6/500 completed with 96 mini-batches.\n",
            "Iteration 7/500 completed with 96 mini-batches.\n",
            "Iteration 8/500 completed with 96 mini-batches.\n",
            "Iteration 9/500 completed with 96 mini-batches.\n",
            "Iteration 10/500 completed with 96 mini-batches.\n",
            "Iteration 11/500 completed with 96 mini-batches.\n",
            "Iteration 12/500 completed with 96 mini-batches.\n",
            "Iteration 13/500 completed with 96 mini-batches.\n",
            "Iteration 14/500 completed with 96 mini-batches.\n",
            "Iteration 15/500 completed with 96 mini-batches.\n",
            "Iteration 16/500 completed with 96 mini-batches.\n",
            "Iteration 17/500 completed with 96 mini-batches.\n",
            "Iteration 18/500 completed with 96 mini-batches.\n",
            "Iteration 19/500 completed with 96 mini-batches.\n",
            "Iteration 20/500 completed with 96 mini-batches.\n",
            "Iteration 21/500 completed with 96 mini-batches.\n",
            "Iteration 22/500 completed with 96 mini-batches.\n",
            "Iteration 23/500 completed with 96 mini-batches.\n",
            "Iteration 24/500 completed with 96 mini-batches.\n",
            "Iteration 25/500 completed with 96 mini-batches.\n",
            "Iteration 26/500 completed with 96 mini-batches.\n",
            "Iteration 27/500 completed with 96 mini-batches.\n",
            "Iteration 28/500 completed with 96 mini-batches.\n",
            "Iteration 29/500 completed with 96 mini-batches.\n",
            "Iteration 30/500 completed with 96 mini-batches.\n",
            "Iteration 31/500 completed with 96 mini-batches.\n",
            "Iteration 32/500 completed with 96 mini-batches.\n",
            "Iteration 33/500 completed with 96 mini-batches.\n",
            "Iteration 34/500 completed with 96 mini-batches.\n",
            "Iteration 35/500 completed with 96 mini-batches.\n",
            "Iteration 36/500 completed with 96 mini-batches.\n",
            "Iteration 37/500 completed with 96 mini-batches.\n",
            "Iteration 38/500 completed with 96 mini-batches.\n",
            "Iteration 39/500 completed with 96 mini-batches.\n",
            "Iteration 40/500 completed with 96 mini-batches.\n",
            "Iteration 41/500 completed with 96 mini-batches.\n",
            "Iteration 42/500 completed with 96 mini-batches.\n",
            "Iteration 43/500 completed with 96 mini-batches.\n",
            "Iteration 44/500 completed with 96 mini-batches.\n",
            "Iteration 45/500 completed with 96 mini-batches.\n",
            "Iteration 46/500 completed with 96 mini-batches.\n",
            "Iteration 47/500 completed with 96 mini-batches.\n",
            "Iteration 48/500 completed with 96 mini-batches.\n",
            "Iteration 49/500 completed with 96 mini-batches.\n",
            "Iteration 50/500 completed with 96 mini-batches.\n",
            "[Iter 0050] Train ELBO: 15012.1523, Val ELBO: 16497.4191, LR: 7.00e-04\n",
            "Iteration 51/500 completed with 96 mini-batches.\n",
            "Iteration 52/500 completed with 96 mini-batches.\n",
            "Iteration 53/500 completed with 96 mini-batches.\n",
            "Iteration 54/500 completed with 96 mini-batches.\n",
            "Iteration 55/500 completed with 96 mini-batches.\n",
            "Iteration 56/500 completed with 96 mini-batches.\n",
            "Iteration 57/500 completed with 96 mini-batches.\n",
            "Iteration 58/500 completed with 96 mini-batches.\n",
            "Iteration 59/500 completed with 96 mini-batches.\n",
            "Iteration 60/500 completed with 96 mini-batches.\n",
            "Iteration 61/500 completed with 96 mini-batches.\n",
            "Iteration 62/500 completed with 96 mini-batches.\n",
            "Iteration 63/500 completed with 96 mini-batches.\n",
            "Iteration 64/500 completed with 96 mini-batches.\n",
            "Iteration 65/500 completed with 96 mini-batches.\n",
            "Iteration 66/500 completed with 96 mini-batches.\n",
            "Iteration 67/500 completed with 96 mini-batches.\n",
            "Iteration 68/500 completed with 96 mini-batches.\n",
            "Iteration 69/500 completed with 96 mini-batches.\n",
            "Iteration 70/500 completed with 96 mini-batches.\n",
            "Iteration 71/500 completed with 96 mini-batches.\n",
            "Iteration 72/500 completed with 96 mini-batches.\n",
            "Iteration 73/500 completed with 96 mini-batches.\n",
            "Iteration 74/500 completed with 96 mini-batches.\n",
            "Iteration 75/500 completed with 96 mini-batches.\n",
            "Iteration 76/500 completed with 96 mini-batches.\n",
            "Iteration 77/500 completed with 96 mini-batches.\n",
            "Iteration 78/500 completed with 96 mini-batches.\n",
            "Iteration 79/500 completed with 96 mini-batches.\n",
            "Iteration 80/500 completed with 96 mini-batches.\n",
            "Iteration 81/500 completed with 96 mini-batches.\n",
            "Iteration 82/500 completed with 96 mini-batches.\n",
            "Iteration 83/500 completed with 96 mini-batches.\n",
            "Iteration 84/500 completed with 96 mini-batches.\n",
            "Iteration 85/500 completed with 96 mini-batches.\n",
            "Iteration 86/500 completed with 96 mini-batches.\n",
            "Iteration 87/500 completed with 96 mini-batches.\n",
            "Iteration 88/500 completed with 96 mini-batches.\n",
            "Iteration 89/500 completed with 96 mini-batches.\n",
            "Iteration 90/500 completed with 96 mini-batches.\n",
            "Iteration 91/500 completed with 96 mini-batches.\n",
            "Iteration 92/500 completed with 96 mini-batches.\n",
            "Iteration 93/500 completed with 96 mini-batches.\n",
            "Iteration 94/500 completed with 96 mini-batches.\n",
            "Iteration 95/500 completed with 96 mini-batches.\n",
            "Iteration 96/500 completed with 96 mini-batches.\n",
            "Iteration 97/500 completed with 96 mini-batches.\n",
            "Iteration 98/500 completed with 96 mini-batches.\n",
            "Iteration 99/500 completed with 96 mini-batches.\n",
            "Iteration 100/500 completed with 96 mini-batches.\n",
            "[Iter 0100] Train ELBO: 9640.7603, Val ELBO: 9548.4689, LR: 7.00e-04\n",
            "Iteration 101/500 completed with 96 mini-batches.\n",
            "Iteration 102/500 completed with 96 mini-batches.\n",
            "Iteration 103/500 completed with 96 mini-batches.\n",
            "Iteration 104/500 completed with 96 mini-batches.\n",
            "Iteration 105/500 completed with 96 mini-batches.\n",
            "Iteration 106/500 completed with 96 mini-batches.\n",
            "Iteration 107/500 completed with 96 mini-batches.\n",
            "Iteration 108/500 completed with 96 mini-batches.\n",
            "Iteration 109/500 completed with 96 mini-batches.\n",
            "Iteration 110/500 completed with 96 mini-batches.\n",
            "Iteration 111/500 completed with 96 mini-batches.\n",
            "Iteration 112/500 completed with 96 mini-batches.\n",
            "Iteration 113/500 completed with 96 mini-batches.\n",
            "Iteration 114/500 completed with 96 mini-batches.\n",
            "Iteration 115/500 completed with 96 mini-batches.\n",
            "Iteration 116/500 completed with 96 mini-batches.\n",
            "Iteration 117/500 completed with 96 mini-batches.\n",
            "Iteration 118/500 completed with 96 mini-batches.\n",
            "Iteration 119/500 completed with 96 mini-batches.\n",
            "Iteration 120/500 completed with 96 mini-batches.\n",
            "Iteration 121/500 completed with 96 mini-batches.\n",
            "Iteration 122/500 completed with 96 mini-batches.\n",
            "Iteration 123/500 completed with 96 mini-batches.\n",
            "Iteration 124/500 completed with 96 mini-batches.\n",
            "Iteration 125/500 completed with 96 mini-batches.\n",
            "Iteration 126/500 completed with 96 mini-batches.\n",
            "Iteration 127/500 completed with 96 mini-batches.\n",
            "Iteration 128/500 completed with 96 mini-batches.\n",
            "Iteration 129/500 completed with 96 mini-batches.\n",
            "Iteration 130/500 completed with 96 mini-batches.\n",
            "Iteration 131/500 completed with 96 mini-batches.\n",
            "Iteration 132/500 completed with 96 mini-batches.\n",
            "Iteration 133/500 completed with 96 mini-batches.\n",
            "Iteration 134/500 completed with 96 mini-batches.\n",
            "Iteration 135/500 completed with 96 mini-batches.\n",
            "Iteration 136/500 completed with 96 mini-batches.\n",
            "Iteration 137/500 completed with 96 mini-batches.\n",
            "Iteration 138/500 completed with 96 mini-batches.\n",
            "Iteration 139/500 completed with 96 mini-batches.\n",
            "Iteration 140/500 completed with 96 mini-batches.\n",
            "Iteration 141/500 completed with 96 mini-batches.\n",
            "Iteration 142/500 completed with 96 mini-batches.\n",
            "Iteration 143/500 completed with 96 mini-batches.\n",
            "Iteration 144/500 completed with 96 mini-batches.\n",
            "Iteration 145/500 completed with 96 mini-batches.\n",
            "Iteration 146/500 completed with 96 mini-batches.\n",
            "Iteration 147/500 completed with 96 mini-batches.\n",
            "Iteration 148/500 completed with 96 mini-batches.\n",
            "Iteration 149/500 completed with 96 mini-batches.\n",
            "Iteration 150/500 completed with 96 mini-batches.\n",
            "[Iter 0150] Train ELBO: 9302.9777, Val ELBO: 9202.6412, LR: 7.00e-04\n",
            "Iteration 151/500 completed with 96 mini-batches.\n",
            "Iteration 152/500 completed with 96 mini-batches.\n",
            "Iteration 153/500 completed with 96 mini-batches.\n",
            "Iteration 154/500 completed with 96 mini-batches.\n",
            "Iteration 155/500 completed with 96 mini-batches.\n",
            "Iteration 156/500 completed with 96 mini-batches.\n",
            "Iteration 157/500 completed with 96 mini-batches.\n",
            "Iteration 158/500 completed with 96 mini-batches.\n",
            "Iteration 159/500 completed with 96 mini-batches.\n",
            "Iteration 160/500 completed with 96 mini-batches.\n",
            "Iteration 161/500 completed with 96 mini-batches.\n",
            "Iteration 162/500 completed with 96 mini-batches.\n",
            "Iteration 163/500 completed with 96 mini-batches.\n",
            "Iteration 164/500 completed with 96 mini-batches.\n",
            "Iteration 165/500 completed with 96 mini-batches.\n",
            "Iteration 166/500 completed with 96 mini-batches.\n",
            "Iteration 167/500 completed with 96 mini-batches.\n",
            "Iteration 168/500 completed with 96 mini-batches.\n",
            "Iteration 169/500 completed with 96 mini-batches.\n",
            "Iteration 170/500 completed with 96 mini-batches.\n",
            "Iteration 171/500 completed with 96 mini-batches.\n",
            "Iteration 172/500 completed with 96 mini-batches.\n",
            "Iteration 173/500 completed with 96 mini-batches.\n",
            "Iteration 174/500 completed with 96 mini-batches.\n",
            "Iteration 175/500 completed with 96 mini-batches.\n",
            "Iteration 176/500 completed with 96 mini-batches.\n",
            "Iteration 177/500 completed with 96 mini-batches.\n",
            "Iteration 178/500 completed with 96 mini-batches.\n",
            "Iteration 179/500 completed with 96 mini-batches.\n",
            "Iteration 180/500 completed with 96 mini-batches.\n",
            "Iteration 181/500 completed with 96 mini-batches.\n",
            "Iteration 182/500 completed with 96 mini-batches.\n",
            "Iteration 183/500 completed with 96 mini-batches.\n",
            "Iteration 184/500 completed with 96 mini-batches.\n",
            "Iteration 185/500 completed with 96 mini-batches.\n",
            "Iteration 186/500 completed with 96 mini-batches.\n",
            "Iteration 187/500 completed with 96 mini-batches.\n",
            "Iteration 188/500 completed with 96 mini-batches.\n",
            "Iteration 189/500 completed with 96 mini-batches.\n",
            "Iteration 190/500 completed with 96 mini-batches.\n",
            "Iteration 191/500 completed with 96 mini-batches.\n",
            "Iteration 192/500 completed with 96 mini-batches.\n",
            "Iteration 193/500 completed with 96 mini-batches.\n",
            "Iteration 194/500 completed with 96 mini-batches.\n",
            "Iteration 195/500 completed with 96 mini-batches.\n",
            "Iteration 196/500 completed with 96 mini-batches.\n",
            "Iteration 197/500 completed with 96 mini-batches.\n",
            "Iteration 198/500 completed with 96 mini-batches.\n",
            "Iteration 199/500 completed with 96 mini-batches.\n",
            "Iteration 200/500 completed with 96 mini-batches.\n",
            "[Iter 0200] Train ELBO: 9043.8472, Val ELBO: 9006.4277, LR: 7.00e-04\n",
            "Iteration 201/500 completed with 96 mini-batches.\n",
            "Iteration 202/500 completed with 96 mini-batches.\n",
            "Iteration 203/500 completed with 96 mini-batches.\n",
            "Iteration 204/500 completed with 96 mini-batches.\n",
            "Iteration 205/500 completed with 96 mini-batches.\n",
            "Iteration 206/500 completed with 96 mini-batches.\n",
            "Iteration 207/500 completed with 96 mini-batches.\n",
            "Iteration 208/500 completed with 96 mini-batches.\n",
            "Iteration 209/500 completed with 96 mini-batches.\n",
            "Iteration 210/500 completed with 96 mini-batches.\n",
            "Iteration 211/500 completed with 96 mini-batches.\n",
            "Iteration 212/500 completed with 96 mini-batches.\n",
            "Iteration 213/500 completed with 96 mini-batches.\n",
            "Iteration 214/500 completed with 96 mini-batches.\n",
            "Iteration 215/500 completed with 96 mini-batches.\n",
            "Iteration 216/500 completed with 96 mini-batches.\n",
            "Iteration 217/500 completed with 96 mini-batches.\n",
            "Iteration 218/500 completed with 96 mini-batches.\n",
            "Iteration 219/500 completed with 96 mini-batches.\n",
            "Iteration 220/500 completed with 96 mini-batches.\n",
            "Iteration 221/500 completed with 96 mini-batches.\n",
            "Iteration 222/500 completed with 96 mini-batches.\n",
            "Iteration 223/500 completed with 96 mini-batches.\n",
            "Iteration 224/500 completed with 96 mini-batches.\n",
            "Iteration 225/500 completed with 96 mini-batches.\n",
            "Iteration 226/500 completed with 96 mini-batches.\n",
            "Iteration 227/500 completed with 96 mini-batches.\n",
            "Iteration 228/500 completed with 96 mini-batches.\n",
            "Iteration 229/500 completed with 96 mini-batches.\n",
            "Iteration 230/500 completed with 96 mini-batches.\n",
            "Iteration 231/500 completed with 96 mini-batches.\n",
            "Iteration 232/500 completed with 96 mini-batches.\n",
            "Iteration 233/500 completed with 96 mini-batches.\n",
            "Iteration 234/500 completed with 96 mini-batches.\n",
            "Iteration 235/500 completed with 96 mini-batches.\n",
            "Iteration 236/500 completed with 96 mini-batches.\n",
            "Iteration 237/500 completed with 96 mini-batches.\n",
            "Iteration 238/500 completed with 96 mini-batches.\n",
            "Iteration 239/500 completed with 96 mini-batches.\n",
            "Iteration 240/500 completed with 96 mini-batches.\n",
            "Iteration 241/500 completed with 96 mini-batches.\n",
            "Iteration 242/500 completed with 96 mini-batches.\n",
            "Iteration 243/500 completed with 96 mini-batches.\n",
            "Iteration 244/500 completed with 96 mini-batches.\n",
            "Iteration 245/500 completed with 96 mini-batches.\n",
            "Iteration 246/500 completed with 96 mini-batches.\n",
            "Iteration 247/500 completed with 96 mini-batches.\n",
            "Iteration 248/500 completed with 96 mini-batches.\n",
            "Iteration 249/500 completed with 96 mini-batches.\n",
            "Iteration 250/500 completed with 96 mini-batches.\n",
            "[Iter 0250] Train ELBO: 8741.8877, Val ELBO: 8724.9750, LR: 7.00e-04\n",
            "Iteration 251/500 completed with 96 mini-batches.\n",
            "Iteration 252/500 completed with 96 mini-batches.\n",
            "Iteration 253/500 completed with 96 mini-batches.\n",
            "Iteration 254/500 completed with 96 mini-batches.\n",
            "Iteration 255/500 completed with 96 mini-batches.\n",
            "Iteration 256/500 completed with 96 mini-batches.\n",
            "Iteration 257/500 completed with 96 mini-batches.\n",
            "Iteration 258/500 completed with 96 mini-batches.\n",
            "Iteration 259/500 completed with 96 mini-batches.\n",
            "Iteration 260/500 completed with 96 mini-batches.\n",
            "Iteration 261/500 completed with 96 mini-batches.\n",
            "Iteration 262/500 completed with 96 mini-batches.\n",
            "Iteration 263/500 completed with 96 mini-batches.\n",
            "Iteration 264/500 completed with 96 mini-batches.\n",
            "Iteration 265/500 completed with 96 mini-batches.\n",
            "Iteration 266/500 completed with 96 mini-batches.\n",
            "Iteration 267/500 completed with 96 mini-batches.\n",
            "Iteration 268/500 completed with 96 mini-batches.\n",
            "Iteration 269/500 completed with 96 mini-batches.\n",
            "Iteration 270/500 completed with 96 mini-batches.\n",
            "Iteration 271/500 completed with 96 mini-batches.\n",
            "Iteration 272/500 completed with 96 mini-batches.\n",
            "Iteration 273/500 completed with 96 mini-batches.\n",
            "Iteration 274/500 completed with 96 mini-batches.\n",
            "Iteration 275/500 completed with 96 mini-batches.\n",
            "Iteration 276/500 completed with 96 mini-batches.\n",
            "Iteration 277/500 completed with 96 mini-batches.\n",
            "Iteration 278/500 completed with 96 mini-batches.\n",
            "Iteration 279/500 completed with 96 mini-batches.\n",
            "Iteration 280/500 completed with 96 mini-batches.\n",
            "Iteration 281/500 completed with 96 mini-batches.\n",
            "Iteration 282/500 completed with 96 mini-batches.\n",
            "Iteration 283/500 completed with 96 mini-batches.\n",
            "Iteration 284/500 completed with 96 mini-batches.\n",
            "Iteration 285/500 completed with 96 mini-batches.\n",
            "Iteration 286/500 completed with 96 mini-batches.\n",
            "Iteration 287/500 completed with 96 mini-batches.\n",
            "Iteration 288/500 completed with 96 mini-batches.\n",
            "Iteration 289/500 completed with 96 mini-batches.\n",
            "Iteration 290/500 completed with 96 mini-batches.\n",
            "Iteration 291/500 completed with 96 mini-batches.\n",
            "Iteration 292/500 completed with 96 mini-batches.\n",
            "Iteration 293/500 completed with 96 mini-batches.\n",
            "Iteration 294/500 completed with 96 mini-batches.\n",
            "Iteration 295/500 completed with 96 mini-batches.\n",
            "Iteration 296/500 completed with 96 mini-batches.\n",
            "Iteration 297/500 completed with 96 mini-batches.\n",
            "Iteration 298/500 completed with 96 mini-batches.\n",
            "Iteration 299/500 completed with 96 mini-batches.\n",
            "Iteration 300/500 completed with 96 mini-batches.\n",
            "[Iter 0300] Reduced learning rate to 6.30e-04\n",
            "[Iter 0300] Train ELBO: 8632.3899, Val ELBO: 8584.5699, LR: 6.30e-04\n",
            "Iteration 301/500 completed with 96 mini-batches.\n",
            "Iteration 302/500 completed with 96 mini-batches.\n",
            "Iteration 303/500 completed with 96 mini-batches.\n",
            "Iteration 304/500 completed with 96 mini-batches.\n",
            "Iteration 305/500 completed with 96 mini-batches.\n",
            "Iteration 306/500 completed with 96 mini-batches.\n",
            "Iteration 307/500 completed with 96 mini-batches.\n",
            "Iteration 308/500 completed with 96 mini-batches.\n",
            "Iteration 309/500 completed with 96 mini-batches.\n",
            "Iteration 310/500 completed with 96 mini-batches.\n",
            "Iteration 311/500 completed with 96 mini-batches.\n",
            "Iteration 312/500 completed with 96 mini-batches.\n",
            "Iteration 313/500 completed with 96 mini-batches.\n",
            "Iteration 314/500 completed with 96 mini-batches.\n",
            "Iteration 315/500 completed with 96 mini-batches.\n",
            "Iteration 316/500 completed with 96 mini-batches.\n",
            "Iteration 317/500 completed with 96 mini-batches.\n",
            "Iteration 318/500 completed with 96 mini-batches.\n",
            "Iteration 319/500 completed with 96 mini-batches.\n",
            "Iteration 320/500 completed with 96 mini-batches.\n",
            "Iteration 321/500 completed with 96 mini-batches.\n",
            "Iteration 322/500 completed with 96 mini-batches.\n",
            "Iteration 323/500 completed with 96 mini-batches.\n",
            "Iteration 324/500 completed with 96 mini-batches.\n",
            "Iteration 325/500 completed with 96 mini-batches.\n",
            "Iteration 326/500 completed with 96 mini-batches.\n",
            "Iteration 327/500 completed with 96 mini-batches.\n",
            "Iteration 328/500 completed with 96 mini-batches.\n",
            "Iteration 329/500 completed with 96 mini-batches.\n",
            "Iteration 330/500 completed with 96 mini-batches.\n",
            "Iteration 331/500 completed with 96 mini-batches.\n",
            "Iteration 332/500 completed with 96 mini-batches.\n",
            "Iteration 333/500 completed with 96 mini-batches.\n",
            "Iteration 334/500 completed with 96 mini-batches.\n",
            "Iteration 335/500 completed with 96 mini-batches.\n",
            "Iteration 336/500 completed with 96 mini-batches.\n",
            "Iteration 337/500 completed with 96 mini-batches.\n",
            "Iteration 338/500 completed with 96 mini-batches.\n",
            "Iteration 339/500 completed with 96 mini-batches.\n",
            "Iteration 340/500 completed with 96 mini-batches.\n",
            "Iteration 341/500 completed with 96 mini-batches.\n",
            "Iteration 342/500 completed with 96 mini-batches.\n",
            "Iteration 343/500 completed with 96 mini-batches.\n",
            "Iteration 344/500 completed with 96 mini-batches.\n",
            "Iteration 345/500 completed with 96 mini-batches.\n",
            "Iteration 346/500 completed with 96 mini-batches.\n",
            "Iteration 347/500 completed with 96 mini-batches.\n",
            "Iteration 348/500 completed with 96 mini-batches.\n",
            "Iteration 349/500 completed with 96 mini-batches.\n",
            "Iteration 350/500 completed with 96 mini-batches.\n",
            "[Iter 0350] Train ELBO: 8562.6741, Val ELBO: 8571.7759, LR: 6.30e-04\n",
            "Iteration 351/500 completed with 96 mini-batches.\n",
            "Iteration 352/500 completed with 96 mini-batches.\n",
            "Iteration 353/500 completed with 96 mini-batches.\n",
            "Iteration 354/500 completed with 96 mini-batches.\n",
            "Iteration 355/500 completed with 96 mini-batches.\n",
            "Iteration 356/500 completed with 96 mini-batches.\n",
            "Iteration 357/500 completed with 96 mini-batches.\n",
            "Iteration 358/500 completed with 96 mini-batches.\n",
            "Iteration 359/500 completed with 96 mini-batches.\n",
            "Iteration 360/500 completed with 96 mini-batches.\n",
            "Iteration 361/500 completed with 96 mini-batches.\n",
            "Iteration 362/500 completed with 96 mini-batches.\n",
            "Iteration 363/500 completed with 96 mini-batches.\n",
            "Iteration 364/500 completed with 96 mini-batches.\n",
            "Iteration 365/500 completed with 96 mini-batches.\n",
            "Iteration 366/500 completed with 96 mini-batches.\n",
            "Iteration 367/500 completed with 96 mini-batches.\n",
            "Iteration 368/500 completed with 96 mini-batches.\n",
            "Iteration 369/500 completed with 96 mini-batches.\n",
            "Iteration 370/500 completed with 96 mini-batches.\n",
            "Iteration 371/500 completed with 96 mini-batches.\n",
            "Iteration 372/500 completed with 96 mini-batches.\n",
            "Iteration 373/500 completed with 96 mini-batches.\n",
            "Iteration 374/500 completed with 96 mini-batches.\n",
            "Iteration 375/500 completed with 96 mini-batches.\n",
            "Iteration 376/500 completed with 96 mini-batches.\n",
            "Iteration 377/500 completed with 96 mini-batches.\n",
            "Iteration 378/500 completed with 96 mini-batches.\n",
            "Iteration 379/500 completed with 96 mini-batches.\n",
            "Iteration 380/500 completed with 96 mini-batches.\n",
            "Iteration 381/500 completed with 96 mini-batches.\n",
            "Iteration 382/500 completed with 96 mini-batches.\n",
            "Iteration 383/500 completed with 96 mini-batches.\n",
            "Iteration 384/500 completed with 96 mini-batches.\n",
            "Iteration 385/500 completed with 96 mini-batches.\n",
            "Iteration 386/500 completed with 96 mini-batches.\n",
            "Iteration 387/500 completed with 96 mini-batches.\n",
            "Iteration 388/500 completed with 96 mini-batches.\n",
            "Iteration 389/500 completed with 96 mini-batches.\n",
            "Iteration 390/500 completed with 96 mini-batches.\n",
            "Iteration 391/500 completed with 96 mini-batches.\n",
            "Iteration 392/500 completed with 96 mini-batches.\n",
            "Iteration 393/500 completed with 96 mini-batches.\n",
            "Iteration 394/500 completed with 96 mini-batches.\n",
            "Iteration 395/500 completed with 96 mini-batches.\n",
            "Iteration 396/500 completed with 96 mini-batches.\n",
            "Iteration 397/500 completed with 96 mini-batches.\n",
            "Iteration 398/500 completed with 96 mini-batches.\n",
            "Iteration 399/500 completed with 96 mini-batches.\n",
            "Iteration 400/500 completed with 96 mini-batches.\n",
            "[Iter 0400] Train ELBO: 8524.2738, Val ELBO: 8500.8293, LR: 6.30e-04\n",
            "Iteration 401/500 completed with 96 mini-batches.\n",
            "Iteration 402/500 completed with 96 mini-batches.\n",
            "Iteration 403/500 completed with 96 mini-batches.\n",
            "Iteration 404/500 completed with 96 mini-batches.\n",
            "Iteration 405/500 completed with 96 mini-batches.\n",
            "Iteration 406/500 completed with 96 mini-batches.\n",
            "Iteration 407/500 completed with 96 mini-batches.\n",
            "Iteration 408/500 completed with 96 mini-batches.\n",
            "Iteration 409/500 completed with 96 mini-batches.\n",
            "Iteration 410/500 completed with 96 mini-batches.\n",
            "Iteration 411/500 completed with 96 mini-batches.\n",
            "Iteration 412/500 completed with 96 mini-batches.\n",
            "Iteration 413/500 completed with 96 mini-batches.\n",
            "Iteration 414/500 completed with 96 mini-batches.\n",
            "Iteration 415/500 completed with 96 mini-batches.\n",
            "Iteration 416/500 completed with 96 mini-batches.\n",
            "Iteration 417/500 completed with 96 mini-batches.\n",
            "Iteration 418/500 completed with 96 mini-batches.\n",
            "Iteration 419/500 completed with 96 mini-batches.\n",
            "Iteration 420/500 completed with 96 mini-batches.\n",
            "Iteration 421/500 completed with 96 mini-batches.\n",
            "Iteration 422/500 completed with 96 mini-batches.\n",
            "Iteration 423/500 completed with 96 mini-batches.\n",
            "Iteration 424/500 completed with 96 mini-batches.\n",
            "Iteration 425/500 completed with 96 mini-batches.\n",
            "Iteration 426/500 completed with 96 mini-batches.\n",
            "Iteration 427/500 completed with 96 mini-batches.\n",
            "Iteration 428/500 completed with 96 mini-batches.\n",
            "Iteration 429/500 completed with 96 mini-batches.\n",
            "Iteration 430/500 completed with 96 mini-batches.\n",
            "Iteration 431/500 completed with 96 mini-batches.\n",
            "Iteration 432/500 completed with 96 mini-batches.\n",
            "Iteration 433/500 completed with 96 mini-batches.\n",
            "Iteration 434/500 completed with 96 mini-batches.\n",
            "Iteration 435/500 completed with 96 mini-batches.\n",
            "Iteration 436/500 completed with 96 mini-batches.\n",
            "Iteration 437/500 completed with 96 mini-batches.\n",
            "Iteration 438/500 completed with 96 mini-batches.\n",
            "Iteration 439/500 completed with 96 mini-batches.\n",
            "Iteration 440/500 completed with 96 mini-batches.\n",
            "Iteration 441/500 completed with 96 mini-batches.\n",
            "Iteration 442/500 completed with 96 mini-batches.\n",
            "Iteration 443/500 completed with 96 mini-batches.\n",
            "Iteration 444/500 completed with 96 mini-batches.\n",
            "Iteration 445/500 completed with 96 mini-batches.\n",
            "Iteration 446/500 completed with 96 mini-batches.\n",
            "Iteration 447/500 completed with 96 mini-batches.\n",
            "Iteration 448/500 completed with 96 mini-batches.\n",
            "Iteration 449/500 completed with 96 mini-batches.\n",
            "Iteration 450/500 completed with 96 mini-batches.\n",
            "[Iter 0450] Train ELBO: 8508.4737, Val ELBO: 8485.3353, LR: 6.30e-04\n",
            "Iteration 451/500 completed with 96 mini-batches.\n",
            "Iteration 452/500 completed with 96 mini-batches.\n",
            "Iteration 453/500 completed with 96 mini-batches.\n",
            "Iteration 454/500 completed with 96 mini-batches.\n",
            "Iteration 455/500 completed with 96 mini-batches.\n",
            "Iteration 456/500 completed with 96 mini-batches.\n",
            "Iteration 457/500 completed with 96 mini-batches.\n",
            "Iteration 458/500 completed with 96 mini-batches.\n",
            "Iteration 459/500 completed with 96 mini-batches.\n",
            "Iteration 460/500 completed with 96 mini-batches.\n",
            "Iteration 461/500 completed with 96 mini-batches.\n",
            "Iteration 462/500 completed with 96 mini-batches.\n",
            "Iteration 463/500 completed with 96 mini-batches.\n",
            "Iteration 464/500 completed with 96 mini-batches.\n",
            "Iteration 465/500 completed with 96 mini-batches.\n",
            "Iteration 466/500 completed with 96 mini-batches.\n",
            "Iteration 467/500 completed with 96 mini-batches.\n",
            "Iteration 468/500 completed with 96 mini-batches.\n",
            "Iteration 469/500 completed with 96 mini-batches.\n",
            "Iteration 470/500 completed with 96 mini-batches.\n",
            "Iteration 471/500 completed with 96 mini-batches.\n",
            "Iteration 472/500 completed with 96 mini-batches.\n",
            "Iteration 473/500 completed with 96 mini-batches.\n",
            "Iteration 474/500 completed with 96 mini-batches.\n",
            "Iteration 475/500 completed with 96 mini-batches.\n",
            "Iteration 476/500 completed with 96 mini-batches.\n",
            "Iteration 477/500 completed with 96 mini-batches.\n",
            "Iteration 478/500 completed with 96 mini-batches.\n",
            "Iteration 479/500 completed with 96 mini-batches.\n",
            "Iteration 480/500 completed with 96 mini-batches.\n",
            "Iteration 481/500 completed with 96 mini-batches.\n",
            "[INFO] Converged at iteration 481\n",
            "Test MSE: 215.7650\n",
            "Test R: 0.7068\n",
            "Sample 95% CI (first 5): [44.881382 44.5663   46.210724 45.426144 45.23284 ]\n"
          ]
        }
      ],
      "source": [
        "# Clear Pyro parameter store\n",
        "pyro.clear_param_store()\n",
        "print(\"WARNING: If shape errors persist, restart the Jupyter kernel to clear cached parameters.\")\n",
        "\n",
        "# Normalize target\n",
        "y_scaler = StandardScaler()\n",
        "y_train_np = y_scaler.fit_transform(y_train_np.reshape(-1, 1)).flatten()\n",
        "y_test_np = y_scaler.transform(y_test_np.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Validation split\n",
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train_np, y_train_np, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "X_train_sub = torch.from_numpy(X_train_sub).float()\n",
        "y_train_sub = torch.from_numpy(y_train_sub).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "y_val = torch.from_numpy(y_val).float()\n",
        "X_test = torch.from_numpy(X_test_np).float()\n",
        "y_test = torch.from_numpy(y_test_np).float()\n",
        "\n",
        "# Subsample validation set\n",
        "val_sample_indices = torch.randperm(X_val.shape[0])[:10000]\n",
        "X_val_sub = X_val[val_sample_indices]\n",
        "y_val_sub = y_val[val_sample_indices]\n",
        "\n",
        "# Hyperparameters\n",
        "n_iterations = 500\n",
        "batch_size = 5000\n",
        "learning_rate = 7e-4\n",
        "hidden_units = 48\n",
        "noise_variance = 2.0\n",
        "tol = 5e-3\n",
        "lr_schedule_step = 300\n",
        "lr_schedule_factor = 0.9\n",
        "\n",
        "# Define BNN model\n",
        "def model(X, y=None):\n",
        "    n_features = X.shape[1]\n",
        "    w1 = pyro.sample(\"w1\", dist.Normal(0., 1.).expand([n_features, hidden_units]).to_event(2))\n",
        "    b1 = pyro.sample(\"b1\", dist.Normal(0., 1.).expand([hidden_units]).to_event(1))\n",
        "    w2 = pyro.sample(\"w2\", dist.Normal(0., 1.).expand([hidden_units, 1]).to_event(2))\n",
        "    b2 = pyro.sample(\"b2\", dist.Normal(0., 1.).expand([1]).to_event(1))\n",
        "\n",
        "    assert w1.shape == (n_features, hidden_units), f\"w1 shape mismatch: {w1.shape}\"\n",
        "    assert b1.shape == (hidden_units,), f\"b1 shape mismatch: {b1.shape}\"\n",
        "    assert w2.shape == (hidden_units, 1), f\"w2 shape mismatch: {w2.shape}\"\n",
        "    assert b2.shape == (1,), f\"b2 shape mismatch: {b2.shape}\"\n",
        "\n",
        "    h = torch.relu(X @ w1 + b1)\n",
        "    out = h @ w2 + b2\n",
        "\n",
        "    with pyro.plate(\"data\", X.shape[0]):\n",
        "        pyro.sample(\"obs\", dist.Normal(out.squeeze(), noise_variance), obs=y)\n",
        "\n",
        "# Define guide\n",
        "def guide(X, y=None):\n",
        "    n_features = X.shape[1]\n",
        "    w1_loc = pyro.param(\"w1_loc_v2\", torch.zeros(n_features, hidden_units))\n",
        "    w1_scale = pyro.param(\"w1_scale_v2\", torch.ones(n_features, hidden_units), constraint=dist.constraints.positive)\n",
        "    b1_loc = pyro.param(\"b1_loc_v2\", torch.zeros(hidden_units))\n",
        "    b1_scale = pyro.param(\"b1_scale_v2\", torch.ones(hidden_units), constraint=dist.constraints.positive)\n",
        "    w2_loc = pyro.param(\"w2_loc_v2\", torch.zeros(hidden_units, 1))\n",
        "    w2_scale = pyro.param(\"w2_scale_v2\", torch.ones(hidden_units, 1), constraint=dist.constraints.positive)\n",
        "    b2_loc = pyro.param(\"b2_loc_v2\", torch.zeros(1))\n",
        "    b2_scale = pyro.param(\"b2_scale_v2\", torch.ones(1), constraint=dist.constraints.positive)\n",
        "\n",
        "    assert w1_loc.shape == (n_features, hidden_units), f\"w1_loc shape mismatch: {w1_loc.shape}\"\n",
        "    assert b1_loc.shape == (hidden_units,), f\"b1_loc shape mismatch: {b1_loc.shape}\"\n",
        "    assert w2_loc.shape == (hidden_units, 1), f\"w2_loc shape mismatch: {w2_loc.shape}\"\n",
        "    assert b2_loc.shape == (1,), f\"b2_loc shape mismatch: {b2_loc.shape}\"\n",
        "\n",
        "    pyro.sample(\"w1\", dist.Normal(w1_loc, w1_scale).to_event(2))\n",
        "    pyro.sample(\"b1\", dist.Normal(b1_loc, b1_scale).to_event(1))\n",
        "    pyro.sample(\"w2\", dist.Normal(w2_loc, w2_scale).to_event(2))\n",
        "    pyro.sample(\"b2\", dist.Normal(b2_loc, b2_scale).to_event(1))\n",
        "\n",
        "# Training setup\n",
        "optimizer = Adam({\"lr\": learning_rate})\n",
        "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
        "loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training loop...\")\n",
        "for i in range(n_iterations):\n",
        "    if i % lr_schedule_step == 0 and i > 0:\n",
        "        learning_rate *= lr_schedule_factor\n",
        "        optimizer = Adam({\"lr\": learning_rate})\n",
        "        svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
        "        print(f\"[Iter {i:04d}] Reduced learning rate to {learning_rate:.2e}\")\n",
        "\n",
        "    indices = torch.randperm(X_train_sub.shape[0])\n",
        "    X_train_sub_shuffled = X_train_sub[indices]\n",
        "    y_train_sub_shuffled = y_train_sub[indices]\n",
        "\n",
        "    mini_batch_count = 0\n",
        "    elbo = 0\n",
        "    for batch_start in range(0, X_train_sub.shape[0], batch_size):\n",
        "        batch_end = min(batch_start + batch_size, X_train_sub.shape[0])\n",
        "        X_batch = X_train_sub_shuffled[batch_start:batch_end]\n",
        "        y_batch = y_train_sub_shuffled[batch_start:batch_end]\n",
        "\n",
        "        elbo += svi.step(X_batch, y_batch) / (X_train_sub.shape[0] / batch_size)\n",
        "        mini_batch_count += 1\n",
        "\n",
        "    val_elbo = 0\n",
        "    for batch_start in range(0, X_val_sub.shape[0], batch_size):\n",
        "        batch_end = min(batch_start + batch_size, X_val_sub.shape[0])\n",
        "        X_batch = X_val_sub[batch_start:batch_end]\n",
        "        y_batch = y_val_sub[batch_start:batch_end]\n",
        "        val_elbo += svi.evaluate_loss(X_batch, y_batch) / (X_val_sub.shape[0] / batch_size)\n",
        "\n",
        "    loss_history.append(elbo)\n",
        "    val_loss_history.append(val_elbo)\n",
        "\n",
        "    if i % 50 == 0 or i < 5:\n",
        "        print(f\"[Iter {i:04d}] Train ELBO: {elbo:.4f}, Val ELBO: {val_elbo:.4f}, LR: {learning_rate:.2e}\")\n",
        "\n",
        "    if i > 50 and abs(loss_history[-10] - loss_history[-1]) < tol:\n",
        "        print(f\"[INFO] Converged at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    print(f\"Iteration {i + 1}/{n_iterations} completed with {mini_batch_count} mini-batches.\")\n",
        "\n",
        "# Predictive distribution\n",
        "def predict(X, n_samples=100):\n",
        "    predictive = pyro.infer.Predictive(model, guide=guide, num_samples=n_samples)\n",
        "    samples = predictive(X)[\"obs\"]\n",
        "    return samples.mean(dim=0).squeeze().numpy()\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = predict(X_test)\n",
        "y_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
        "y_test_np = y_scaler.inverse_transform(y_test.numpy().reshape(-1, 1)).flatten()\n",
        "mse = mean_squared_error(y_test_np, y_pred)\n",
        "r2 = r2_score(y_test_np, y_pred)\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "print(f\"Test R: {r2:.4f}\")\n",
        "\n",
        "# Residual plot\n",
        "#plt.scatter(y_pred, y_test_np - y_pred, alpha=0.1)\n",
        "#plt.axhline(0, color='r')\n",
        "#plt.xlabel(\"Predicted Listening Time (minutes)\")\n",
        "#plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
        "#plt.title(\"Residual Plot\")\n",
        "#plt.show()\n",
        "\n",
        "# Prediction intervals\n",
        "n_samples = 500\n",
        "y_samples = predict(X_test, n_samples=n_samples)\n",
        "y_samples = y_scaler.inverse_transform(y_samples.reshape(-1, 1)).reshape(n_samples, -1)\n",
        "intervals = 1.96 * y_samples.std(axis=0)\n",
        "print(f\"Sample 95% CI (first 5): {intervals[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ShmQmXW8-aFq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShmQmXW8-aFq",
        "outputId": "fc02a262-a44b-4a02-cf2d-870b961cc737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Episode_Length_minutes  Host_Popularity_percentage  \\\n",
            "0               -0.001908                   -0.944340   \n",
            "1               -0.002233                    0.505836   \n",
            "2               -0.001971                    0.357234   \n",
            "3               -0.001676                   -1.587260   \n",
            "4               -0.001950                   -0.070651   \n",
            "\n",
            "   Guest_Popularity_percentage  Number_of_Ads  Episode_Number  Genre_Business  \\\n",
            "0                     0.035627      -0.083252        0.769228           False   \n",
            "1                     0.036803      -0.317204       -1.013125           False   \n",
            "2                     1.766796      -0.317204       -1.440889           False   \n",
            "3                    -0.026284       0.150699        0.769228           False   \n",
            "4                    -1.611295       0.150699       -0.050654           False   \n",
            "\n",
            "   Genre_Comedy  Genre_Education  Genre_Health  Genre_Lifestyle  ...  \\\n",
            "0         False             True         False            False  ...   \n",
            "1         False            False         False            False  ...   \n",
            "2          True            False         False            False  ...   \n",
            "3          True            False         False            False  ...   \n",
            "4         False            False         False             True  ...   \n",
            "\n",
            "   Publication_Day_Thursday  Publication_Day_Tuesday  \\\n",
            "0                     False                    False   \n",
            "1                     False                    False   \n",
            "2                     False                    False   \n",
            "3                     False                    False   \n",
            "4                     False                    False   \n",
            "\n",
            "   Publication_Day_Wednesday  Publication_Time_Afternoon  \\\n",
            "0                      False                       False   \n",
            "1                      False                       False   \n",
            "2                      False                       False   \n",
            "3                      False                       False   \n",
            "4                       True                       False   \n",
            "\n",
            "   Publication_Time_Evening  Publication_Time_Morning  Publication_Time_Night  \\\n",
            "0                      True                     False                   False   \n",
            "1                     False                      True                   False   \n",
            "2                      True                     False                   False   \n",
            "3                     False                      True                   False   \n",
            "4                     False                      True                   False   \n",
            "\n",
            "   Episode_Sentiment_Negative  Episode_Sentiment_Neutral  \\\n",
            "0                       False                       True   \n",
            "1                       False                       True   \n",
            "2                       False                      False   \n",
            "3                       False                      False   \n",
            "4                       False                       True   \n",
            "\n",
            "   Episode_Sentiment_Positive  \n",
            "0                       False  \n",
            "1                       False  \n",
            "2                        True  \n",
            "3                        True  \n",
            "4                       False  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/test.csv')\n",
        "df = df.drop([\"id\", \"Podcast_Name\"], axis=1)\n",
        "\n",
        "df[\"Episode_Title\"] = df[\"Episode_Title\"].str.replace(\"Episode \", \"\", regex=False)\n",
        "df[\"Episode_Number\"] = df[\"Episode_Title\"].str.extract(r\"(\\d+)$\").astype(float)\n",
        "df = df.drop(\"Episode_Title\", axis=1)\n",
        "\n",
        "numerical_cols = [\n",
        "    \"Episode_Length_minutes\",\n",
        "    \"Host_Popularity_percentage\",\n",
        "    \"Guest_Popularity_percentage\",\n",
        "    \"Number_of_Ads\"\n",
        "]\n",
        "\n",
        "for col in numerical_cols:\n",
        "    median_val = df[col].median()\n",
        "    df[col] = df[col].fillna(median_val)\n",
        "\n",
        "categorical_cols = [\"Genre\", \"Publication_Day\", \"Publication_Time\", \"Episode_Sentiment\"]\n",
        "df = pd.get_dummies(df, columns=categorical_cols)\n",
        "\n",
        "numerical_cols = [\"Episode_Number\"] + numerical_cols\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "zzhkcFOhImaR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzhkcFOhImaR",
        "outputId": "f19abc79-6698-4b2d-8a97-b9bfa198e4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id  Listening_Time_minutes\n",
            "0  750000               31.941841\n",
            "1  750001               71.183640\n",
            "2  750002               58.668865\n",
            "3  750003                5.741311\n",
            "4  750004               52.789505\n"
          ]
        }
      ],
      "source": [
        "# Simplified prediction function\n",
        "def predict_listening_time(test_df, model, guide, y_scaler, n_samples=100):\n",
        "    \"\"\"\n",
        "    Predict Listening_Time_minutes for a test DataFrame using the trained BNN model.\n",
        "\n",
        "    Args:\n",
        "        test_df (pd.DataFrame): Test data with same features as training.\n",
        "        model (callable): Trained BNN model function.\n",
        "        guide (callable): Trained BNN guide function.\n",
        "        y_scaler (StandardScaler): Scaler for target (Listening_Time_minutes).\n",
        "        n_samples (int): Number of Monte Carlo samples for prediction (default: 100).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing 'ID' and 'Predicted Listening Time'.\n",
        "    \"\"\"\n",
        "    # Convert DataFrame to NumPy\n",
        "    X_test_np = test_df.to_numpy().astype(np.float32)\n",
        "\n",
        "    # Convert to torch tensor\n",
        "    X_test = torch.from_numpy(X_test_np).float()\n",
        "\n",
        "    # Predictive distribution\n",
        "    def predict(X, n_samples=n_samples):\n",
        "        predictive = pyro.infer.Predictive(model, guide=guide, num_samples=n_samples)\n",
        "        samples = predictive(X)[\"obs\"]\n",
        "        return samples.mean(dim=0).squeeze().numpy()\n",
        "\n",
        "    # Get predictions (normalized)\n",
        "    y_pred = predict(X_test, n_samples=n_samples)\n",
        "\n",
        "    # Denormalize predictions\n",
        "    y_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Create IDs starting from 750000\n",
        "    ids = np.arange(750000, 750000 + len(y_pred))\n",
        "\n",
        "    # Create DataFrame to store IDs and predictions\n",
        "    results_df = pd.DataFrame({\n",
        "        'id': ids,\n",
        "        'Listening_Time_minutes': y_pred\n",
        "    })\n",
        "\n",
        "    # Save the results to a CSV file\n",
        "    results_df.to_csv(\"predictions6.csv\", index=False)\n",
        "\n",
        "    return results_df  # Optionally return the DataFrame\n",
        "\n",
        "# Example usage:\n",
        "# Assume model, guide, y_scaler are defined and test data is available in df\n",
        "predictions_df = predict_listening_time(df, model, guide, y_scaler, n_samples=100)\n",
        "\n",
        "print(predictions_df.head())  # Print first few rows of the predictions DataFrame\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}